{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# image resize and padding\n",
        "\n",
        "여러 크기의 이미지들을 한꺼번에 리사이즈하고 패딩처리하는 소스입니다.\n",
        "\n",
        "구글에서 리사이즈 하는 소스와 강사님의 패딩 처리 소스를 응용하였습니다.\n",
        "\n",
        "** xml에서 txt로 변환하는 부분의 경우 기존 코드를 가져와서 중심이 좌측 상단에 있습니다.*\n",
        "\n"
      ],
      "metadata": {
        "id": "NFdZQ8JBvjYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 함수\n"
      ],
      "metadata": {
        "id": "GayLFZkozu4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SetImagePadding**\n",
        "\n",
        " *이미지 패딩처리*\n",
        "* image_path: 원본 이미지 경로\n",
        "* save_image_path: 저장할 이미지 경로\n",
        "* finalTargetSize: 패딩 처리한 이후의 이미지 사이즈\n",
        "\n",
        "**SetImageResizeNPadding**\n",
        "\n",
        " *이미지 리사이즈 및 패딩 처리*\n",
        "* image_path : 원본 이미지 경로\n",
        "* save_image_path : 저장할 이미지 경로\n",
        "* targetWidth : 리사이즈할 이미지 사이즈\n",
        "* targetHeight : 리사이즈할 이미지 사이즈\n",
        "* finalTargetSize : 패딩 처리 이후 최종 이미지 사이즈\n",
        "\n",
        "**SetBboxPadding**\n",
        "\n",
        " *바운딩 박스 패딩처리*\n",
        "* xmin : 바운딩 박스 좌표 xmin\n",
        "* ymin : 바운딩 박스 좌표 ymin\n",
        "* xmax : 바운딩 박스 좌표 xmax\n",
        "* ymax : 바운딩 박스 좌표 ymax\n",
        "* targetWidth : 패딩 전 이미지 크기\n",
        "* targetHeight : 패딩 전 이미지 크기\n",
        "* finalTargetSize : 패딩 후 최종 이미지 크기\n",
        "\n",
        "**SetBboxResizeNPadding**\n",
        "\n",
        " *바운딩 박스 리사이즈 및 패딩 처리*\n",
        "* imageToPredict: 원본 이미지\n",
        "* xmin : 바운딩 박스 좌표 xmin\n",
        "* ymin : 바운딩 박스 좌표 ymin\n",
        "* xmax : 바운딩 박스 좌표 xmax\n",
        "* ymax : 바운딩 박스 좌표 ymax\n",
        "* targetWidth : 리사이즈 후이면서 패딩 전 이미지 크기\n",
        "* targetHeight : 리사이즈 후이면서 패딩 전 이미지 크기\n",
        "* finalTargetSize : 패딩 후 최종 이미지 크기\n",
        "\n",
        "**SaveResizeNPadding(xml_path, current_img_path, new_image_path, new_txt_path, targetWidth, targetHeight, finalTargetSize, label2idx)**\n",
        "\n",
        " *이미지 패딩처리*\n",
        "* xml_path : 원본 xml 경로\n",
        "* current_img_path : 원본 이미지 경로\n",
        "* new_image_path : 이미지를 리사이즈/패딩 처리하여 변경된 이미지를 저장할 경로\n",
        "* new_txt_path : xml 내 값을 리사이즈/패딩 처리하여 변경된 내용을 .txt로 저장할 경로\n",
        "* targetWidth : 리사이즈 후이면서 패딩 전 이미지 크기\n",
        "* targetHeight : 리사이즈 후이면서 패딩 전 이미지 크기\n",
        "* finalTargetSize : 패딩 후 최종 이미지 크기\n",
        "* label2idx: 라벨명을 숫자 라벨로 바꿔주기 위한 dictionary"
      ],
      "metadata": {
        "id": "VpDO52Vv2HEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXARTzKNva5v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def SetImagePadding(image_path, save_image_path, finalTargetSize):\n",
        "    # 이미지 받을 경로, 저장할 경로, 중간 너비, 중간 높이, 최종 크기(정사각형이므로 길이하나만)\n",
        "    # load image\n",
        "    imageToPredict = cv2.imread(image_path, 3) # 단일 이미지 읽기\n",
        "    img = np.array(imageToPredict); # 이미지 행렬화\n",
        "\n",
        "    # padding\n",
        "    y_zero, x_zero, target_height, target_width = (0, 0, img.shape[0], img.shape[1]) # 바뀐 이미지의 패딩계산을 위한 크기\n",
        "\n",
        "    # 그림 주변에 검은색으로 칠하기\n",
        "    padding_width = (finalTargetSize - (target_width - x_zero))/2  # w_x = (targetWidth - 그림)을 뺀 나머지 영역 크기 [ 그림나머지/2 [그림] 그림나머지/2 ]\n",
        "    padding_height = (finalTargetSize - (target_height - y_zero))/2\n",
        "\n",
        "    if(padding_width < 0):         # 크기가 -면 0으로 지정.\n",
        "        padding_width = 0\n",
        "    elif(padding_height < 0):\n",
        "        padding_height = 0\n",
        "\n",
        "    M = np.float32([[1, 0, padding_width], [0, 1, padding_height]])  #(2*3 이차원 행렬)\n",
        "    img_re = cv2.warpAffine(img, M, (finalTargetSize, finalTargetSize)) # 패딩 실행\n",
        "\n",
        "    # save image\n",
        "    cv2.imwrite(save_image_path, img_re) # 저장\n",
        "\n",
        "\n",
        "def SetImageResizeNPadding(image_path, save_image_path, targetWidth, targetHeight, finalTargetSize):\n",
        "    # 이미지 받을 경로, 저장할 경로, 중간 너비, 중간 높이, 최종 크기(정사각형이므로 길이하나만)\n",
        "    # load image\n",
        "    imageToPredict = cv2.imread(image_path, 3) # 단일 이미지 읽기\n",
        "    img = np.array(imageToPredict); # 이미지 행렬화\n",
        "\n",
        "    # resize\n",
        "    img = cv2.resize(imageToPredict, (targetWidth, targetHeight)); # 이미지 리사이즈\n",
        "    img = np.array(img); # resize 된 이미지 행렬화\n",
        "\n",
        "    # padding\n",
        "    y_zero, x_zero, target_height, target_width = (0, 0, img.shape[0], img.shape[1]) # 바뀐 이미지의 패딩계산을 위한 크기\n",
        "\n",
        "    # 그림 주변에 검은색으로 칠하기\n",
        "    padding_width = (finalTargetSize - (target_width - x_zero))/2  # w_x = (targetWidth - 그림)을 뺀 나머지 영역 크기 [ 그림나머지/2 [그림] 그림나머지/2 ]\n",
        "    padding_height = (finalTargetSize - (target_height - y_zero))/2\n",
        "\n",
        "    if(padding_width < 0):         # 크기가 -면 0으로 지정.\n",
        "        padding_width = 0\n",
        "    elif(padding_height < 0):\n",
        "        padding_height = 0\n",
        "\n",
        "    M = np.float32([[1, 0, padding_width], [0, 1, padding_height]])  #(2*3 이차원 행렬)\n",
        "    img_re = cv2.warpAffine(img, M, (finalTargetSize, finalTargetSize)) # 패딩 실행\n",
        "\n",
        "    # save image\n",
        "    cv2.imwrite(save_image_path, img_re) # 저장\n",
        "\n",
        "    # return img, img_re\n",
        "\n",
        "def SetBboxPadding(xmin, ymin, xmax, ymax, targetWidth, targetHeight, finalTargetSize):\n",
        "    \n",
        "    # padding\n",
        "    y_zero, x_zero, target_height, target_width = (0, 0, targetHeight, targetWidth) # 원점설정과 패딩 추가 전 이미지 크기\n",
        "\n",
        "    # 그림 주변에 검은색으로 칠하기\n",
        "    padding_width = (finalTargetSize - (target_width - x_zero))/2  # padding_width = (targetWidth - 그림)을 뺀 나머지 영역 크기 [ 그림나머지/2 [그림] 그림나머지/2 ]\n",
        "    padding_height = (finalTargetSize - (target_height - y_zero))/2  # 패딩크기\n",
        "\n",
        "    if(padding_width < 0):         # 크기가 -면 0으로 지정.\n",
        "        padding_width = 0\n",
        "    elif(padding_height < 0):\n",
        "        padding_height = 0\n",
        "\n",
        "    return (int(xmin + padding_width), int(ymin + padding_height), int(xmax + padding_width), int(ymax + padding_height))\n",
        "\n",
        "\n",
        "def SetBboxResizeNPadding(imageToPredict, xmin, ymin, xmax, ymax, targetWidth, targetHeight, finalTargetSize):\n",
        "    # imageToPredict <- img # 패딩 없이 받아와서 패딩 추가 후 bbox 정렬\n",
        "    img = np.array(imageToPredict); # 행렬화\n",
        "\n",
        "    original_img_height = imageToPredict.shape[0] # 이미지의 높이\n",
        "    original_img_width = imageToPredict.shape[1] # 너비\n",
        "    x_scale = targetWidth / original_img_width # 패딩을 제외한 크기로 줄이기 위한 x비율\n",
        "    y_scale = targetHeight / original_img_height # 패딩을 제외한 크기로 줄이기 위한 y비율\n",
        "    # print(original_img_height, original_img_width, targetWidth, targetHeight)\n",
        "    # print(xmin, ymin, xmax, ymax)\n",
        "    xmin = int(np.round(xmin * x_scale)) # 비율에 맞추어 위치 재정렬 / 소수점 반올림 \n",
        "    ymin = int(np.round(ymin * y_scale))  \n",
        "    xmax = int(np.round(xmax * x_scale))\n",
        "    ymax = int(np.round(ymax * y_scale))\n",
        "    # print(xmin, ymin, xmax, ymax)\n",
        "    # padding\n",
        "    y_zero, x_zero, target_height, target_width = (0, 0, targetHeight, targetWidth) # 원점설정과 패딩 추가 전 이미지 크기\n",
        "\n",
        "    # 그림 주변에 검은색으로 칠하기\n",
        "    padding_width = (finalTargetSize - (target_width - x_zero))/2  # padding_width = (targetWidth - 그림)을 뺀 나머지 영역 크기 [ 그림나머지/2 [그림] 그림나머지/2 ]\n",
        "    padding_height = (finalTargetSize - (target_height - y_zero))/2  # 패딩크기\n",
        "    # print(padding_width, padding_height)\n",
        "    if(padding_width < 0):         # 크기가 -면 0으로 지정.\n",
        "        padding_width = 0\n",
        "    elif(padding_height < 0):\n",
        "        padding_height = 0\n",
        "\n",
        "    return (int(xmin + padding_width), int(ymin + padding_height), int(xmax + padding_width), int(ymax + padding_height))\n",
        "\n",
        "\n",
        "# xml 폴더경로, img 폴더경로, 새로운 img 저장할 경로, 새로운 txt 저장할 경로\n",
        "def SaveResizeNPadding(xml_path, current_img_path, new_image_path, new_txt_path, targetWidth, targetHeight, finalTargetSize, label2idx):\n",
        "    # load xml\n",
        "    for xml_file in tqdm(glob.glob(xml_path + '/*.xml')): # 경로상 xml 모두 경로 포함 불러오기\n",
        "\n",
        "        img_file_name = xml_file.split('/')[-1][:-4]                      # 파일명\n",
        "        ouput_txt_filename = f'{new_txt_path}' + img_file_name + '.txt'   # 원하는 경로 / f'{dest_path}' +\n",
        "        current_img_filename = current_img_path + img_file_name  + '.jpg' # 현재 xml 파일과 짝인 image 파일\n",
        "        new_img_filename = new_image_path + img_file_name + '_{0}_{0}.jpg'.format(finalTargetSize, finalTargetSize) # 만들어줄 image 파일\n",
        "        \n",
        "        tree = ET.parse(xml_file) # xml을 읽기 \n",
        "        root = tree.getroot()     # 변환\n",
        "\n",
        "        original_image_width = int(root.find('size').find('width').text)      # 원래 이미지 크기\n",
        "        original_image_height = int(root.find('size').find('height').text)\n",
        "        # 이미지 크기가 바꾸고자 하는 이미지와 같을 경우 리사이즈를 안하고 패딩 처리만 하기 위해\n",
        "        is_original_size_same = targetWidth == original_image_width or targetHeight == original_image_height   \n",
        "        # 이미지 크기가 가로-세로, 세로-가로가 하나라도 바꾸고자 하는 이미지와 같을 경우 같은 구간은 맞춰주기 위해 \n",
        "        is_original_size_small = targetWidth == original_image_height or targetHeight == original_image_width\n",
        "\n",
        "        # image resize and padding\n",
        "        if is_original_size_same:\n",
        "          img_only_padding = SetImagePadding(current_img_filename, new_img_filename, finalTargetSize)\n",
        "        elif is_original_size_small:\n",
        "          # 최종 이미지와 원본 이미지와의 scale 계산\n",
        "          original_image_scale = finalTargetSize/original_image_width           \n",
        "          # 현재는 640 x 480 -> 480 x 480 같이 height가 같을 경우만 처리함. 재사용시 width가 같은 경우도 처리 필요\n",
        "          targetHeight = int(original_image_height * original_image_scale)    \n",
        "          SetImageResizeNPadding(current_img_filename, new_img_filename, targetWidth, targetHeight, finalTargetSize)\n",
        "        else:\n",
        "          SetImageResizeNPadding(current_img_filename, new_img_filename, targetWidth, targetHeight, finalTargetSize)\n",
        "\n",
        "        original_img = cv2.imread(current_img_filename)\n",
        "        f = open(ouput_txt_filename, 'w') # 작성 시작\n",
        "\n",
        "        # bbox resize and padding\n",
        "        # get xmin, ymin, xmax, ymax, width, height\n",
        "        for member in root.findall('object'):           # 변환된 xml에서 객체수만큼 반복\n",
        "            bbx = member.find('bndbox')                 # bbox 태그\n",
        "            label = member.find('name').text            # trash 종류\n",
        "            xmin = float(bbx.find('xmin').text)         # bbox 초기 xmin\n",
        "            ymin = float(bbx.find('ymin').text)         # bbox 초기 ymin\n",
        "            xmax = float(bbx.find('xmax').text)         # bbox 초기 xmax\n",
        "            ymax = float(bbx.find('ymax').text)         # bbox 초기 ymax\n",
        "\n",
        "            # 패딩 후 bbox 값을 튜플로 각 변수에 할당\n",
        "            if is_original_size_same:\n",
        "                (bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax) = SetBboxPadding(xmin, ymin, xmax, ymax, original_image_width, original_image_height, finalTargetSize)\n",
        "            else:\n",
        "                (bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax) = SetBboxResizeNPadding(original_img, xmin, ymin, xmax, ymax, \n",
        "                                                                              targetWidth, targetHeight, finalTargetSize)\n",
        "            \n",
        "            label_idx = label2idx[label]                    # trash의 라벨을 붙여준다\n",
        "            x, y = bbox_xmin / finalTargetSize, bbox_ymin / finalTargetSize # 최종 이미지 크기에서의 비율로 변환\n",
        "            w, h = (bbox_xmax - bbox_xmin) / finalTargetSize, (bbox_ymax - bbox_ymin) / finalTargetSize        \n",
        "\n",
        "            info = f'{label_idx} {x} {y} {w} {h}' # 라벨과 나머지 값들을 통합\n",
        "            \n",
        "            f.write(info+'\\n') # 파일 쓰기\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실행"
      ],
      "metadata": {
        "id": "8M7oG1O6zy3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label2idx = {'bundle of ropes' : 0,'bundle of rope' : 0, 'rope' : 1, 'circular fish trap' : 2,'eel fish trap' : 3,'fish net' : 4,\n",
        "                 'rectangular fish trap' : 5,'spring fish trap' : 6, 'tire' : 7, 'wood' : 8, 'other objects' : 9, 'other objets':9,\n",
        "             'othe objects':9}"
      ],
      "metadata": {
        "id": "f0Aef-Aw1weX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sonar 480 x 480\n",
        "\n",
        "SaveResizeNPadding('/content/drive/MyDrive/Alpaco Object Detection/final/sonar_label/'\n",
        "                  , '/content/drive/MyDrive/Alpaco Object Detection/final/sonar_image/'\n",
        "                  , '/content/drive/MyDrive/Alpaco Object Detection/final/sonar_image_480/'\n",
        "                  , '/content/drive/MyDrive/Alpaco Object Detection/final/sonar_label_480/'\n",
        "                  , 480, 480, 480, label2idx)"
      ],
      "metadata": {
        "id": "ZpscqHiVyG1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SaveResizeNPadding('/content/drive/MyDrive/Colab_Notebooks/Object_Detection_Project/final/underwater_label', \n",
        "                   '/content/drive/MyDrive/Colab_Notebooks/Object_Detection_Project/final/underwater_image/', \n",
        "                   '/content/img/', '/content/txt/', 640, 480, 640, label2idx)"
      ],
      "metadata": {
        "id": "nZbd3nFr10Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 참고\n",
        "\n",
        "### xml 구조"
      ],
      "metadata": {
        "id": "nAQ7WJtG2c8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
        "<annotation>\n",
        "  <folder>[sonar]</folder>\n",
        "  <filename>rope_spring fish trap_20111026_003_20027_12.jpg</filename>\n",
        "  <path>../../[image]/[sonar]/rope_spring fish trap_20111026_003_20027_12.jpg</path>\n",
        "  <size>\n",
        "    <width>640</width>\n",
        "    <height>640</height>\n",
        "    <depth>3</depth>\n",
        "  </size>\n",
        "  <commoninfo>\n",
        "    <datasetname>sonar dataset</datasetname>\n",
        "    <createdate>2021-04-22 09:48:39.0</createdate>\n",
        "  </commoninfo>\n",
        "  <metainfo>\n",
        "    <device>SonarBeam S-150</device>\n",
        "    <viewername>PostScan</viewername>\n",
        "    <viewerversion>v7.39</viewerversion>\n",
        "    <location>\n",
        "      <name>the West sea</name>\n",
        "      <latitude>\n",
        "        <DMS/>\n",
        "        <DMM/>\n",
        "        <DD>35.979781</DD>\n",
        "      </latitude>\n",
        "      <longitude>\n",
        "        <DMS/>\n",
        "        <DMM/>\n",
        "        <DD>126.583333</DD>\n",
        "      </longitude>\n",
        "    </location>\n",
        "    <depth-of-water>0.0</depth-of-water>\n",
        "    <temperature/>\n",
        "    <NTU/>\n",
        "  </metainfo>\n",
        "  <object>\n",
        "    <name>rope</name>\n",
        "    <bndbox>\n",
        "      <xmin>276.57142857142856</xmin>\n",
        "      <ymin>399.7142857142857</ymin>\n",
        "      <xmax>634.2857142857142</xmax>\n",
        "      <ymax>640.0</ymax>\n",
        "      <width>357.71428571428567</width>\n",
        "      <height>240.28571428571428</height>\n",
        "    </bndbox>\n",
        "    <grade>A</grade>\n",
        "  </object>\n",
        "  <object>\n",
        "    <name>spring fish trap</name>\n",
        "    <bndbox>\n",
        "      <xmin>532.6051805492795</xmin>\n",
        "      <ymin>318.0456496385726</ymin>\n",
        "      <xmax>576.4202215874342</xmax>\n",
        "      <ymax>336.0663520010395</ymax>\n",
        "      <width>43.81504103815473</width>\n",
        "      <height>18.020702362466864</height>\n",
        "    </bndbox>\n",
        "    <grade>A</grade>\n",
        "  </object>\n",
        "</annotation>"
      ],
      "metadata": {
        "id": "kATQRM6G2ikL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# yolov4 tensorflow evaluate.py\n",
        "\n",
        "저희 조의 경우 이미지 이름에 띄어쓰기가 있었기 때문에 tensorflow-yolov4-tflite github 소스에서 evaluate.py 를 일부 수정하여 실행시켰습니다.\n",
        "\n",
        "수정한 부분은 # start 부터 # end 까지입니다.\n",
        "\n",
        "확장자가 .jpg 였기 때문에 저렇게 처리했습니다,,"
      ],
      "metadata": {
        "id": "npNT9K25vtk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from core.yolov4 import filter_boxes\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "import core.utils as utils\n",
        "from core.config import cfg\n",
        "flags.DEFINE_string('weights', './checkpoints/yolov4-416',\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_string('framework', 'tf', 'select model type in (tf, tflite, trt)'\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_string('model', 'yolov4', 'yolov3 or yolov4')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 480, 'resize images to')\n",
        "flags.DEFINE_string('annotation_path', \"./data/dataset/val2017.txt\", 'annotation path')\n",
        "flags.DEFINE_string('write_image_path', \"./data/detection/\", 'write image path')\n",
        "flags.DEFINE_float('iou', 0.5, 'iou threshold')\n",
        "flags.DEFINE_float('score', 0.25, 'score threshold')\n",
        "def main(_argv):\n",
        "    INPUT_SIZE = FLAGS.size\n",
        "    STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
        "    CLASSES = utils.read_class_names(cfg.YOLO.CLASSES)\n",
        "    predicted_dir_path = './mAP/predicted'\n",
        "    ground_truth_dir_path = './mAP/ground-truth'\n",
        "    if os.path.exists(predicted_dir_path): shutil.rmtree(predicted_dir_path)\n",
        "    if os.path.exists(ground_truth_dir_path): shutil.rmtree(ground_truth_dir_path)\n",
        "    if os.path.exists(cfg.TEST.DECTECTED_IMAGE_PATH): shutil.rmtree(cfg.TEST.DECTECTED_IMAGE_PATH)\n",
        "    os.mkdir(predicted_dir_path)\n",
        "    os.mkdir(ground_truth_dir_path)\n",
        "    os.mkdir(cfg.TEST.DECTECTED_IMAGE_PATH)\n",
        "    # Build Model\n",
        "    if FLAGS.framework == 'tflite':\n",
        "        interpreter = tf.lite.Interpreter(model_path=FLAGS.weights)\n",
        "        interpreter.allocate_tensors()\n",
        "        input_details = interpreter.get_input_details()\n",
        "        output_details = interpreter.get_output_details()\n",
        "        print(input_details)\n",
        "        print(output_details)\n",
        "    else:\n",
        "        saved_model_loaded = tf.saved_model.load(FLAGS.weights, tags=[tag_constants.SERVING])\n",
        "        infer = saved_model_loaded.signatures['serving_default']\n",
        "    num_lines = sum(1 for line in open(FLAGS.annotation_path))\n",
        "    with open(cfg.TEST.ANNOT_PATH, 'r') as annotation_file:\n",
        "        for num, line in enumerate(annotation_file):\n",
        "            # start\n",
        "            image_jpg_file_path = line.strip().split('.jpg')[0] + '.jpg'\n",
        "            temp_annotation = line.strip().split('.jpg')[1].strip().split()\n",
        "            annotation = []\n",
        "            annotation.append(image_jpg_file_path)\n",
        "            annotation.extend(temp_annotation)\n",
        "            # end\n",
        "            image_path = annotation[0]\n",
        "            image_name = image_path.split('/')[-1]\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            bbox_data_gt = np.array([list(map(int, box.split(','))) for box in annotation[1:]])\n",
        "            if len(bbox_data_gt) == 0:\n",
        "                bboxes_gt = []\n",
        "                classes_gt = []\n",
        "            else:\n",
        "                bboxes_gt, classes_gt = bbox_data_gt[:, :4], bbox_data_gt[:, 4]\n",
        "            ground_truth_path = os.path.join(ground_truth_dir_path, str(num) + '.txt')\n",
        "            print('=> ground truth of %s:' % image_name)\n",
        "            num_bbox_gt = len(bboxes_gt)\n",
        "            with open(ground_truth_path, 'w') as f:\n",
        "                for i in range(num_bbox_gt):\n",
        "                    class_name = CLASSES[classes_gt[i]]\n",
        "                    xmin, ymin, xmax, ymax = list(map(str, bboxes_gt[i]))\n",
        "                    bbox_mess = ' '.join([class_name, xmin, ymin, xmax, ymax]) + '\\n'\n",
        "                    f.write(bbox_mess)\n",
        "                    print('\\t' + str(bbox_mess).strip())\n",
        "            print('=> predict result of %s:' % image_name)\n",
        "            predict_result_path = os.path.join(predicted_dir_path, str(num) + '.txt')\n",
        "            # Predict Process\n",
        "            image_size = image.shape[:2]\n",
        "            # image_data = utils.image_preprocess(np.copy(image), [INPUT_SIZE, INPUT_SIZE])\n",
        "            image_data = cv2.resize(np.copy(image), (INPUT_SIZE, INPUT_SIZE))\n",
        "            image_data = image_data / 255.\n",
        "            image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "            if FLAGS.framework == 'tflite':\n",
        "                interpreter.set_tensor(input_details[0]['index'], image_data)\n",
        "                interpreter.invoke()\n",
        "                pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
        "                if FLAGS.model == 'yolov4' and FLAGS.tiny == True:\n",
        "                    boxes, pred_conf = filter_boxes(pred[1], pred[0], score_threshold=0.25)\n",
        "                else:\n",
        "                    boxes, pred_conf = filter_boxes(pred[0], pred[1], score_threshold=0.25)\n",
        "            else:\n",
        "                batch_data = tf.constant(image_data)\n",
        "                pred_bbox = infer(batch_data)\n",
        "                for key, value in pred_bbox.items():\n",
        "                    boxes = value[:, :, 0:4]\n",
        "                    pred_conf = value[:, :, 4:]\n",
        "            boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
        "                boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
        "                scores=tf.reshape(\n",
        "                    pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
        "                max_output_size_per_class=50,\n",
        "                max_total_size=50,\n",
        "                iou_threshold=FLAGS.iou,\n",
        "                score_threshold=FLAGS.score\n",
        "            )\n",
        "            boxes, scores, classes, valid_detections = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
        "            # if cfg.TEST.DECTECTED_IMAGE_PATH is not None:\n",
        "            #     image_result = utils.draw_bbox(np.copy(image), [boxes, scores, classes, valid_detections])\n",
        "            #     cv2.imwrite(cfg.TEST.DECTECTED_IMAGE_PATH + image_name, image_result)\n",
        "            with open(predict_result_path, 'w') as f:\n",
        "                image_h, image_w, _ = image.shape\n",
        "                for i in range(valid_detections[0]):\n",
        "                    if int(classes[0][i]) < 0 or int(classes[0][i]) > NUM_CLASS: continue\n",
        "                    coor = boxes[0][i]\n",
        "                    coor[0] = int(coor[0] * image_h)\n",
        "                    coor[2] = int(coor[2] * image_h)\n",
        "                    coor[1] = int(coor[1] * image_w)\n",
        "                    coor[3] = int(coor[3] * image_w)\n",
        "                    score = scores[0][i]\n",
        "                    class_ind = int(classes[0][i])\n",
        "                    class_name = CLASSES[class_ind]\n",
        "                    score = '%.4f' % score\n",
        "                    ymin, xmin, ymax, xmax = list(map(str, coor))\n",
        "                    bbox_mess = ' '.join([class_name, score, xmin, ymin, xmax, ymax]) + '\\n'\n",
        "                    f.write(bbox_mess)\n",
        "                    print('\\t' + str(bbox_mess).strip())\n",
        "            print(num, num_lines)\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        app.run(main)\n",
        "    except SystemExit:\n",
        "        pass"
      ],
      "metadata": {
        "id": "I9p4klOP6jj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}